# Sign-Language-Recognition

# American Sign Language Recognition System 

A deep learning-based system for recognizing American Sign Language (ASL) gestures using a combination of **Convolutional Neural Networks (CNN)** for Alphabets and numbers, **Multi-Layer Perceptrons (MLP)** for static two-hand gestures, and **Long Short-Term Memory (LSTM)** networks for dynamic sign recognition.

## Project Overview

This project aims to create an intelligent system capable of recognizing both static and dynamic ASL gestures. It consists of three core modules:

- üñºÔ∏è **CNN Model** ‚Äî Recognizes static signs (A-Z, 0‚Äì9) from cropped hand images.
- üß† **MLP Model** ‚Äî Classifies static two-hand signs based on landmark coordinates.
- üé• **LSTM Model** ‚Äî Detects dynamic signs using time-sequenced landmark data.

 ## Directions

 Each folder contains data collection, pre-processing, training and testing files for each type of model: CNN, MLP, and LSTM



