{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d0da14-a135-4a8c-959e-65342b5360f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Data_BothHands_Body_Face\\\\Friend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m training_data\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Create and shuffle the training data\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m training_data \u001b[38;5;241m=\u001b[39m create_training_data()\n\u001b[0;32m     44\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(training_data)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Split features (X) and labels (y)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m, in \u001b[0;36mcreate_training_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATADIR, category)\n\u001b[0;32m     31\u001b[0m class_num \u001b[38;5;241m=\u001b[39m CATEGORIES\u001b[38;5;241m.\u001b[39mindex(category)\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(path):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         landmarks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, file))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Data_BothHands_Body_Face\\\\Friend'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dataset directory and categories\n",
    "DATADIR = \"Data_BothHands_Body_Face\"\n",
    "CATEGORIES = [\"Friend\", \"Sorry\",\"Please\",\"Eat\",\"want\",\"More\",\"Help\",\"Stop\",\"Mother\",\"Yes\",\"No\",\"Thanks\",\"Father\",\"I love you\",\"you\",\"Hello\",\"Mine\",\"Pain\",\"I\"]  # Add your labels\n",
    "\n",
    "# Define the expected number of landmarks\n",
    "# MediaPipe Pose has 33 landmarks, and each hand has 21 landmarks.\n",
    "# Total landmarks = 33 (pose) + 21 (left hand) + 21 (right hand) = 75 landmarks.\n",
    "# Each landmark has 3 values (x, y, z), so the total size is 75 * 3 = 225.\n",
    "EXPECTED_SIZE = 225  # 75 landmarks * 3 values (x, y, z)\n",
    "\n",
    "# Function to pad or truncate landmarks to a fixed size\n",
    "def normalize_landmarks(landmarks, expected_size):\n",
    "    if len(landmarks) < expected_size:\n",
    "        # Pad with zeros if the array is too small\n",
    "        landmarks = np.pad(landmarks, (0, expected_size - len(landmarks)), mode='constant')\n",
    "    elif len(landmarks) > expected_size:\n",
    "        # Truncate if the array is too large\n",
    "        landmarks = landmarks[:expected_size]\n",
    "    return landmarks\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def create_training_data():\n",
    "    training_data = []\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for file in os.listdir(path):\n",
    "            try:\n",
    "                landmarks = np.load(os.path.join(path, file))\n",
    "                # Normalize the landmarks to a fixed size\n",
    "                landmarks = normalize_landmarks(landmarks, EXPECTED_SIZE)\n",
    "                training_data.append([landmarks, class_num])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file {file}: {e}\")\n",
    "    return training_data\n",
    "\n",
    "# Create and shuffle the training data\n",
    "training_data = create_training_data()\n",
    "np.random.shuffle(training_data)\n",
    "\n",
    "# Split features (X) and labels (y)\n",
    "X = np.array([item[0] for item in training_data])\n",
    "y = np.array([item[1] for item in training_data])\n",
    "\n",
    "# Save data using pickle\n",
    "with open(\"X_BothHands.pickle\", \"wb\") as f:\n",
    "    pickle.dump(X, f)\n",
    "with open(\"y_BothHands.pickle\", \"wb\") as f:\n",
    "    pickle.dump(y, f)\n",
    "\n",
    "print(\"Data preprocessing complete. Features and labels saved as X_BothHands.pickle and y_BothHands.pickle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9918c-4486-4b58-b911-bcc44ed2785d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
