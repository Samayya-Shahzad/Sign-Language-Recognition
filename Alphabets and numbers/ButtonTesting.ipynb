{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71412b86-5943-47b7-851f-92628f42d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.keras.models import load_model\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3  # For text-to-speech\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "offset = 20\n",
    "imgSize = 100\n",
    "labels = []\n",
    "model = None\n",
    "cap = None  # Declare it globally so it can be accessed in multiple functions\n",
    "detector = None  # Declare HandDetector globally\n",
    "\n",
    "# Text-to-Speech Engine\n",
    "engine = pyttsx3.init()\n",
    "rate = engine.getProperty('rate')\n",
    "engine.setProperty('rate', rate - 60)\n",
    "\n",
    "recorded_gestures = []\n",
    "\n",
    "# Load the model and labels\n",
    "def load_model_safe(model_path, label_list):\n",
    "    global model, labels\n",
    "    if os.path.exists(model_path):\n",
    "        model = load_model(model_path)\n",
    "        labels = label_list\n",
    "        start_prediction_screen()\n",
    "        \n",
    "    else:\n",
    "        messagebox.showerror(\"Error\", f\"Model file '{model_path}' not found.\")\n",
    "\n",
    "def load_alphabet_model():\n",
    "    load_model_safe('asl_alphabet_model.h5', ['A','B','C','D','dot','E','F','G','H','I','J','K','L','M','N','num','O','P','Q','R','S','space','T','U','V','W','words','X','Y','Z'])\n",
    "\n",
    "def load_number_model():\n",
    "    load_model_safe('asl_number_model.h5', ['0','1','2','3','4','5','6','7','8','9','alphabets','dot','space','words'])\n",
    "\n",
    "def load_word_model():\n",
    "    load_model_safe('asl_words_model.h5', [\"alphabets\",\"dot\",\"Hello\", \"I love you\",\"No\", \"num\", \"Ok\",\"space\", \"Thanks\", \"Yes\"])\n",
    "\n",
    "# Gesture Recording Functions\n",
    "def on_button_click():\n",
    "    gesture = text_box.get()\n",
    "    if gesture:\n",
    "        recorded_gestures.append(gesture)\n",
    "        update_recorded_text()\n",
    "        messagebox.showinfo(\"Gesture Recognized\", f\"Recognized Gesture: {gesture}\")\n",
    "    else:\n",
    "        messagebox.showwarning(\"No Gesture\", \"Please wait for a gesture to be recognized.\")\n",
    "\n",
    "def speak_text():\n",
    "    text = recorded_text.cget(\"text\")\n",
    "    if text:\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        messagebox.showwarning(\"No Text\", \"No recorded gestures to speak.\")\n",
    "\n",
    "def clear_text():\n",
    "    if recorded_gestures:\n",
    "        recorded_gestures.clear()\n",
    "        update_recorded_text()\n",
    "        messagebox.showinfo(\"Cleared\", \"Recorded gestures have been cleared.\")\n",
    "    else:\n",
    "        messagebox.showwarning(\"No Text\", \"No recorded gestures to clear.\")\n",
    "\n",
    "# Prediction Screen\n",
    "def start_prediction_screen():\n",
    "    global root, canvas, cap, detector, text_box, recorded_text\n",
    "\n",
    "    selection_root.destroy()  # Close the selection screen\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    detector = HandDetector(maxHands=1)\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"ASL Prediction\")\n",
    "    root.geometry(\"800x700\")\n",
    "\n",
    "    # Canvas for webcam feed\n",
    "    canvas = tk.Canvas(root, width=640, height=480)\n",
    "    canvas.pack()\n",
    "\n",
    "    # Text box for recognized gesture\n",
    "    text_box = tk.Entry(root, font=('Arial', 24), width=10)\n",
    "    text_box.pack(pady=10)\n",
    "\n",
    "    # Recorded gestures label\n",
    "    recorded_label = tk.Label(root, text=\"Recorded Gestures:\", font=('Arial', 14))\n",
    "    recorded_label.pack(pady=10)\n",
    "\n",
    "    recorded_text = tk.Label(root, text=\"\", font=('Arial', 14), width=20, height=2, relief=\"solid\", wraplength=300)\n",
    "    recorded_text.pack(pady=10)\n",
    "\n",
    "    # Button frame for gesture controls\n",
    "    button_frame = tk.Frame(root)\n",
    "    button_frame.pack(pady=10)\n",
    "\n",
    "    tk.Button(button_frame, text=\"Record Gesture\", font=('Arial', 14), command=on_button_click, bg=\"lightblue\").grid(row=0, column=0, padx=10)\n",
    "    tk.Button(button_frame, text=\"Speak\", font=('Arial', 14), command=speak_text, bg=\"lightgreen\").grid(row=0, column=1, padx=10)\n",
    "    tk.Button(button_frame, text=\"Clear\", font=('Arial', 14), command=clear_text, bg=\"red\").grid(row=0, column=2, padx=10)\n",
    "\n",
    "    # Buttons for switching models\n",
    "    switch_frame = tk.Frame(root)\n",
    "    switch_frame.pack(pady=10)\n",
    "\n",
    "    tk.Button(switch_frame, text=\"Alphabets\", font=('Arial', 14), command=load_alphabet_model, bg=\"lightblue\").grid(row=0, column=0, padx=10)\n",
    "    tk.Button(switch_frame, text=\"Numbers\", font=('Arial', 14), command=load_number_model, bg=\"lightgreen\").grid(row=0, column=1, padx=10)\n",
    "    tk.Button(switch_frame, text=\"Words\", font=('Arial', 14), command=load_word_model, bg=\"lightyellow\").grid(row=0, column=2, padx=10)\n",
    "\n",
    "    update_frame()  # Start updating frames\n",
    "    root.mainloop()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to update the text box with recognized gesture\n",
    "def update_text_box(gesture):\n",
    "    text_box.delete(0, tk.END)\n",
    "    text_box.insert(0, gesture)\n",
    "\n",
    "# Function to update recorded gestures display\n",
    "def update_recorded_text():\n",
    "    recorded_text.config(text=\" \".join(recorded_gestures))\n",
    "\n",
    "# Function to process each frame\n",
    "def update_frame():\n",
    "    global cap, canvas, detector\n",
    "\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture frame.\")\n",
    "        return\n",
    "\n",
    "    imgOutput = img.copy()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "        imgCrop = img[max(0, y - offset):min(y + h + offset, img.shape[0]),\n",
    "                      max(0, x - offset):min(x + w + offset, img.shape[1])]\n",
    "\n",
    "        try:\n",
    "            aspectRatio = h / w\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wGap + wCal] = imgResize\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hGap + hCal, :] = imgResize\n",
    "\n",
    "            imgWhite = imgWhite / 255.0\n",
    "            imgWhite = np.expand_dims(imgWhite, axis=0)\n",
    "\n",
    "            predictions = model.predict(imgWhite)\n",
    "            classIndex = np.argmax(predictions)\n",
    "            gestureName = labels[classIndex]\n",
    "\n",
    "            cv2.putText(imgOutput, gestureName, (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.rectangle(imgOutput, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            update_text_box(gestureName)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error processing hand:\", e)\n",
    "\n",
    "    imgOutput = cv2.cvtColor(imgOutput, cv2.COLOR_BGR2RGB)\n",
    "    imgOutput = Image.fromarray(imgOutput)\n",
    "    imgOutput = ImageTk.PhotoImage(imgOutput)\n",
    "\n",
    "    canvas.create_image(0, 0, image=imgOutput, anchor=tk.NW)\n",
    "    canvas.image = imgOutput\n",
    "\n",
    "    root.after(50, update_frame)  # 20 FPS\n",
    "\n",
    "# Selection screen\n",
    "selection_root = tk.Tk()\n",
    "selection_root.title(\"Select ASL Model\")\n",
    "selection_root.geometry(\"400x300\")\n",
    "\n",
    "tk.Label(selection_root, text=\"Select ASL Model\", font=('Arial', 24)).pack(pady=20)\n",
    "tk.Button(selection_root, text=\"Alphabets\", font=('Arial', 18), command=load_alphabet_model).pack(pady=10)\n",
    "tk.Button(selection_root, text=\"Numbers\", font=('Arial', 18), command=load_number_model).pack(pady=10)\n",
    "tk.Button(selection_root, text=\"Words\", font=('Arial', 18), command=load_word_model).pack(pady=10)\n",
    "\n",
    "selection_root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d62ccc-b866-4683-a6bb-597e44cc1467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
